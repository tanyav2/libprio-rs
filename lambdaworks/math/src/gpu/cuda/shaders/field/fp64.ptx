//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-33191640
// Cuda compilation tools, release 12.2, V12.2.140
// Based on NVVM 7.0.1
//

.version 8.2
.target sm_52, debug
.address_size 64

	// .globl	_Z13reverse_indexjj
.weak .func  (.param .align 8 .b8 func_retval0[8]) _ZNK4Fp64plES_
(
	.param .b64 _ZNK4Fp64plES__param_0,
	.param .align 8 .b8 _ZNK4Fp64plES__param_1[8]
)
;
.weak .func  (.param .align 8 .b8 func_retval0[8]) _ZNK4Fp64mlES_
(
	.param .b64 _ZNK4Fp64mlES__param_0,
	.param .align 8 .b8 _ZNK4Fp64mlES__param_1[8]
)
;
.weak .func  (.param .align 8 .b8 func_retval0[8]) _ZNK4Fp64miES_
(
	.param .b64 _ZNK4Fp64miES__param_0,
	.param .align 8 .b8 _ZNK4Fp64miES__param_1[8]
)
;
.weak .func  (.param .align 8 .b8 func_retval0[8]) _ZNK4Fp643powEy
(
	.param .b64 _ZNK4Fp643powEy_param_0,
	.param .b64 _ZNK4Fp643powEy_param_1
)
;
.weak .func _ZN4Fp64C1Ey
(
	.param .b64 _ZN4Fp64C1Ey_param_0,
	.param .b64 _ZN4Fp64C1Ey_param_1
)
;
.func  (.param .b32 func_retval0) __clz
(
	.param .b32 __clz_param_0
)
;
.func  (.param .b32 func_retval0) __brev
(
	.param .b32 __brev_param_0
)
;

.visible .func  (.param .b32 func_retval0) _Z13reverse_indexjj(
	.param .b32 _Z13reverse_indexjj_param_0,
	.param .b32 _Z13reverse_indexjj_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<10>;
	.loc	2 5 0
$L__func_begin0:
	.loc	2 5 0


	ld.param.u32 	%r4, [_Z13reverse_indexjj_param_0];
	ld.param.u32 	%r5, [_Z13reverse_indexjj_param_1];
$L__tmp0:
	.loc	2 7 5
	setp.eq.s32 	%p1, %r5, 1;
	not.pred 	%p2, %p1;
	@%p2 bra 	$L__BB0_2;
	bra.uni 	$L__BB0_1;

$L__BB0_1:
$L__tmp1:
	.loc	2 9 9
	mov.b32 	%r1, %r4;
	mov.u32 	%r9, %r1;
	bra.uni 	$L__BB0_3;
$L__tmp2:

$L__BB0_2:
	.loc	2 13 9
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.b32 	[param0+0], %r4;
	.param .b32 retval0;
	call.uni (retval0), 
	__brev, 
	(
	param0
	);
	ld.param.b32 	%r6, [retval0+0];
	} // callseq 0
	{ // callseq 1, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.b32 	[param0+0], %r5;
	.param .b32 retval0;
	call.uni (retval0), 
	__clz, 
	(
	param0
	);
	ld.param.b32 	%r7, [retval0+0];
	} // callseq 1
	add.s32 	%r8, %r7, 1;
	shr.u32 	%r2, %r6, %r8;
	mov.u32 	%r9, %r2;
	bra.uni 	$L__BB0_3;

$L__BB0_3:
	mov.u32 	%r3, %r9;
	st.param.b32 	[func_retval0+0], %r3;
	ret;
$L__tmp3:
$L__func_end0:

}
	// .weak	_Z21_radix2_dit_butterflyI4Fp64EvPT_PKS1_ii
.weak .func _Z21_radix2_dit_butterflyI4Fp64EvPT_PKS1_ii(
	.param .b64 _Z21_radix2_dit_butterflyI4Fp64EvPT_PKS1_ii_param_0,
	.param .b64 _Z21_radix2_dit_butterflyI4Fp64EvPT_PKS1_ii_param_1,
	.param .b32 _Z21_radix2_dit_butterflyI4Fp64EvPT_PKS1_ii_param_2,
	.param .b32 _Z21_radix2_dit_butterflyI4Fp64EvPT_PKS1_ii_param_3
)
{
	.local .align 8 .b8 	__local_depot1[40];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<3>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<31>;
	.loc	3 4 0
$L__func_begin1:
	.loc	3 4 0


	mov.u64 	%SPL, __local_depot1;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd1, [_Z21_radix2_dit_butterflyI4Fp64EvPT_PKS1_ii_param_0];
	ld.param.u64 	%rd2, [_Z21_radix2_dit_butterflyI4Fp64EvPT_PKS1_ii_param_1];
	ld.param.u32 	%r2, [_Z21_radix2_dit_butterflyI4Fp64EvPT_PKS1_ii_param_2];
	ld.param.u32 	%r3, [_Z21_radix2_dit_butterflyI4Fp64EvPT_PKS1_ii_param_3];
$L__tmp4:
	.loc	3 9 5
	mov.u32 	%r4, %ntid.x;
	mov.u32 	%r5, %ctaid.x;
	mul.lo.s32 	%r6, %r4, %r5;
	mov.u32 	%r7, %tid.x;
	add.s32 	%r1, %r6, %r7;
$L__tmp5:
	.loc	3 11 5
	setp.ge.s32 	%p1, %r1, %r3;
	not.pred 	%p2, %p1;
	@%p2 bra 	$L__BB1_2;
	bra.uni 	$L__BB1_1;

$L__BB1_1:
	bra.uni 	$L__BB1_3;

$L__BB1_2:
	.loc	3 14 5
	shr.s32 	%r8, %r3, %r2;
$L__tmp6:
	.loc	3 15 5
	div.s32 	%r9, %r1, %r8;
$L__tmp7:
	.loc	3 17 5
	sub.s32 	%r10, %r8, 1;
	and.b32  	%r11, %r1, %r10;
$L__tmp8:
	.loc	3 18 5
	mul.lo.s32 	%r12, %r1, 2;
	sub.s32 	%r13, %r12, %r11;
$L__tmp9:
	.loc	3 20 5
	cvt.s64.s32 	%rd3, %r9;
	shl.b64 	%rd4, %rd3, 3;
	add.s64 	%rd5, %rd2, %rd4;
	ld.u64 	%rd6, [%rd5];
	st.u64 	[%SP+0], %rd6;
	.loc	3 21 5
	cvt.s64.s32 	%rd7, %r13;
	shl.b64 	%rd8, %rd7, 3;
	add.s64 	%rd9, %rd1, %rd8;
	ld.u64 	%rd10, [%rd9];
	st.u64 	[%SP+8], %rd10;
	.loc	3 22 5
	add.s32 	%r14, %r13, %r8;
	cvt.s64.s32 	%rd11, %r14;
	shl.b64 	%rd12, %rd11, 3;
	add.s64 	%rd13, %rd1, %rd12;
	ld.u64 	%rd14, [%rd13];
	st.u64 	[%SP+16], %rd14;
	.loc	3 24 5
	ld.u64 	%rd15, [%SP+16];
	add.u64 	%rd16, %SP, 0;
	{ // callseq 2, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd16;
	.param .align 8 .b8 param1[8];
	st.param.b64 	[param1+0], %rd15;
	.param .align 8 .b8 retval0[8];
	call.uni (retval0), 
	_ZNK4Fp64mlES_, 
	(
	param0, 
	param1
	);
	ld.param.b64 	%rd17, [retval0+0];
	} // callseq 2
	add.u64 	%rd18, %SP, 8;
	{ // callseq 3, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd18;
	.param .align 8 .b8 param1[8];
	st.param.b64 	[param1+0], %rd17;
	.param .align 8 .b8 retval0[8];
	call.uni (retval0), 
	_ZNK4Fp64plES_, 
	(
	param0, 
	param1
	);
	ld.param.b64 	%rd19, [retval0+0];
	} // callseq 3
	st.u64 	[%SP+24], %rd19;
	.loc	3 25 5
	ld.u64 	%rd20, [%SP+16];
	{ // callseq 4, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd16;
	.param .align 8 .b8 param1[8];
	st.param.b64 	[param1+0], %rd20;
	.param .align 8 .b8 retval0[8];
	call.uni (retval0), 
	_ZNK4Fp64mlES_, 
	(
	param0, 
	param1
	);
	ld.param.b64 	%rd21, [retval0+0];
	} // callseq 4
	{ // callseq 5, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd18;
	.param .align 8 .b8 param1[8];
	st.param.b64 	[param1+0], %rd21;
	.param .align 8 .b8 retval0[8];
	call.uni (retval0), 
	_ZNK4Fp64miES_, 
	(
	param0, 
	param1
	);
	ld.param.b64 	%rd22, [retval0+0];
	} // callseq 5
	st.u64 	[%SP+32], %rd22;
	.loc	3 27 5
	cvt.s64.s32 	%rd23, %r13;
	shl.b64 	%rd24, %rd23, 3;
	add.s64 	%rd25, %rd1, %rd24;
	ld.u64 	%rd26, [%SP+24];
	st.u64 	[%rd25], %rd26;
	.loc	3 28 5
	add.s32 	%r15, %r13, %r8;
	cvt.s64.s32 	%rd27, %r15;
	shl.b64 	%rd28, %rd27, 3;
	add.s64 	%rd29, %rd1, %rd28;
	ld.u64 	%rd30, [%SP+32];
	st.u64 	[%rd29], %rd30;
	.loc	3 29 1
	bra.uni 	$L__BB1_3;

$L__BB1_3:
	ret;
$L__tmp10:
$L__func_end1:

}
	// .weak	_ZNK4Fp64plES_
.weak .func  (.param .align 8 .b8 func_retval0[8]) _ZNK4Fp64plES_(
	.param .b64 _ZNK4Fp64plES__param_0,
	.param .align 8 .b8 _ZNK4Fp64plES__param_1[8]
)
{
	.local .align 8 .b8 	__local_depot2[16];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<4>;
	.reg .b64 	%rd<9>;
	.loc	1 14 0
$L__func_begin2:
	.loc	1 14 0


	mov.u64 	%SPL, __local_depot2;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd1, [_ZNK4Fp64plES__param_0];
	ld.param.u64 	%rd2, [_ZNK4Fp64plES__param_1];
	st.u64 	[%SP+0], %rd2;
$L__tmp11:
	.loc	1 15 9
	ld.u64 	%rd3, [%rd1];
	ld.u64 	%rd4, [%SP+0];
	add.s64 	%rd5, %rd3, %rd4;
	rem.u64 	%rd6, %rd5, -4294967295;
	add.u64 	%rd7, %SP, 8;
	{ // callseq 6, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd7;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd6;
	call.uni 
	_ZN4Fp64C1Ey, 
	(
	param0, 
	param1
	);
	} // callseq 6
	setp.ne.s64 	%p1, %rd1, 0;
	not.pred 	%p2, %p1;
	not.pred 	%p3, %p2;
	@%p3 bra 	$L__BB2_2;
	bra.uni 	$L__BB2_1;

$L__BB2_1:
	bra.uni 	$L__BB2_2;

$L__BB2_2:
	ld.u64 	%rd8, [%SP+8];
	st.param.b64 	[func_retval0+0], %rd8;
	ret;
$L__tmp12:
$L__func_end2:

}
	// .weak	_ZNK4Fp64mlES_
.weak .func  (.param .align 8 .b8 func_retval0[8]) _ZNK4Fp64mlES_(
	.param .b64 _ZNK4Fp64mlES__param_0,
	.param .align 8 .b8 _ZNK4Fp64mlES__param_1[8]
)
{
	.local .align 8 .b8 	__local_depot3[16];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<4>;
	.reg .b64 	%rd<9>;
	.loc	1 22 0
$L__func_begin3:
	.loc	1 22 0


	mov.u64 	%SPL, __local_depot3;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd1, [_ZNK4Fp64mlES__param_0];
	ld.param.u64 	%rd2, [_ZNK4Fp64mlES__param_1];
	st.u64 	[%SP+0], %rd2;
$L__tmp13:
	.loc	1 23 9
	ld.u64 	%rd3, [%rd1];
	ld.u64 	%rd4, [%SP+0];
	mul.lo.s64 	%rd5, %rd3, %rd4;
	rem.u64 	%rd6, %rd5, -4294967295;
	add.u64 	%rd7, %SP, 8;
	{ // callseq 7, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd7;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd6;
	call.uni 
	_ZN4Fp64C1Ey, 
	(
	param0, 
	param1
	);
	} // callseq 7
	setp.ne.s64 	%p1, %rd1, 0;
	not.pred 	%p2, %p1;
	not.pred 	%p3, %p2;
	@%p3 bra 	$L__BB3_2;
	bra.uni 	$L__BB3_1;

$L__BB3_1:
	bra.uni 	$L__BB3_2;

$L__BB3_2:
	ld.u64 	%rd8, [%SP+8];
	st.param.b64 	[func_retval0+0], %rd8;
	ret;
$L__tmp14:
$L__func_end3:

}
	// .weak	_ZNK4Fp64miES_
.weak .func  (.param .align 8 .b8 func_retval0[8]) _ZNK4Fp64miES_(
	.param .b64 _ZNK4Fp64miES__param_0,
	.param .align 8 .b8 _ZNK4Fp64miES__param_1[8]
)
{
	.local .align 8 .b8 	__local_depot4[16];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<4>;
	.reg .b64 	%rd<10>;
	.loc	1 18 0
$L__func_begin4:
	.loc	1 18 0


	mov.u64 	%SPL, __local_depot4;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd1, [_ZNK4Fp64miES__param_0];
	ld.param.u64 	%rd2, [_ZNK4Fp64miES__param_1];
	st.u64 	[%SP+0], %rd2;
$L__tmp15:
	.loc	1 19 9
	ld.u64 	%rd3, [%rd1];
	add.s64 	%rd4, %rd3, -4294967295;
	ld.u64 	%rd5, [%SP+0];
	sub.s64 	%rd6, %rd4, %rd5;
	rem.u64 	%rd7, %rd6, -4294967295;
	add.u64 	%rd8, %SP, 8;
	{ // callseq 8, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd8;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd7;
	call.uni 
	_ZN4Fp64C1Ey, 
	(
	param0, 
	param1
	);
	} // callseq 8
	setp.ne.s64 	%p1, %rd1, 0;
	not.pred 	%p2, %p1;
	not.pred 	%p3, %p2;
	@%p3 bra 	$L__BB4_2;
	bra.uni 	$L__BB4_1;

$L__BB4_1:
	bra.uni 	$L__BB4_2;

$L__BB4_2:
	ld.u64 	%rd9, [%SP+8];
	st.param.b64 	[func_retval0+0], %rd9;
	ret;
$L__tmp16:
$L__func_end4:

}
	// .weak	_Z14_calc_twiddlesI4Fp64EvPT_RKS1_i
.weak .func _Z14_calc_twiddlesI4Fp64EvPT_RKS1_i(
	.param .b64 _Z14_calc_twiddlesI4Fp64EvPT_RKS1_i_param_0,
	.param .b64 _Z14_calc_twiddlesI4Fp64EvPT_RKS1_i_param_1,
	.param .b32 _Z14_calc_twiddlesI4Fp64EvPT_RKS1_i_param_2
)
{
	.local .align 8 .b8 	__local_depot5[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<3>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<10>;
	.loc	4 7 0
$L__func_begin5:
	.loc	4 7 0


	mov.u64 	%SPL, __local_depot5;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd1, [_Z14_calc_twiddlesI4Fp64EvPT_RKS1_i_param_0];
	ld.param.u64 	%rd2, [_Z14_calc_twiddlesI4Fp64EvPT_RKS1_i_param_1];
	ld.param.u32 	%r2, [_Z14_calc_twiddlesI4Fp64EvPT_RKS1_i_param_2];
$L__tmp17:
	.loc	4 9 5
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %ctaid.x;
	mul.lo.s32 	%r5, %r3, %r4;
	mov.u32 	%r6, %tid.x;
	add.s32 	%r1, %r5, %r6;
$L__tmp18:
	.loc	4 10 5
	setp.ge.u32 	%p1, %r1, %r2;
	not.pred 	%p2, %p1;
	@%p2 bra 	$L__BB5_2;
	bra.uni 	$L__BB5_1;

$L__BB5_1:
	bra.uni 	$L__BB5_3;

$L__BB5_2:
	.loc	4 13 5
	ld.u64 	%rd3, [%rd2];
	st.u64 	[%SP+0], %rd3;
	.loc	4 14 5
	cvt.u64.u32 	%rd4, %r1;
	add.u64 	%rd5, %SP, 0;
	{ // callseq 9, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd5;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd4;
	.param .align 8 .b8 retval0[8];
	call.uni (retval0), 
	_ZNK4Fp643powEy, 
	(
	param0, 
	param1
	);
	ld.param.b64 	%rd6, [retval0+0];
	} // callseq 9
	cvt.u64.u32 	%rd7, %r1;
	shl.b64 	%rd8, %rd7, 3;
	add.s64 	%rd9, %rd1, %rd8;
	st.u64 	[%rd9], %rd6;
	.loc	4 15 1
	bra.uni 	$L__BB5_3;

$L__BB5_3:
	ret;
$L__tmp19:
$L__func_end5:

}
	// .weak	_ZNK4Fp643powEy
.weak .func  (.param .align 8 .b8 func_retval0[8]) _ZNK4Fp643powEy(
	.param .b64 _ZNK4Fp643powEy_param_0,
	.param .b64 _ZNK4Fp643powEy_param_1
)
{
	.local .align 8 .b8 	__local_depot6[16];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<8>;
	.reg .b64 	%rd<16>;
	.loc	1 32 0
$L__func_begin6:
	.loc	1 32 0


	mov.u64 	%SPL, __local_depot6;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd4, [_ZNK4Fp643powEy_param_0];
	ld.param.u64 	%rd5, [_ZNK4Fp643powEy_param_1];
$L__tmp20:
	.loc	1 33 9
	ld.u64 	%rd6, [%rd4];
	st.u64 	[%SP+0], %rd6;
	.loc	1 34 9
	mov.u64 	%rd7, 1;
	st.u64 	[%SP+8], %rd7;
	.loc	1 35 9
	mov.u64 	%rd15, %rd5;
$L__tmp21:
	bra.uni 	$L__BB6_1;

$L__BB6_1:
	mov.u64 	%rd1, %rd15;
$L__tmp22:
	setp.ne.s64 	%p1, %rd1, 0;
	not.pred 	%p2, %p1;
	@%p2 bra 	$L__BB6_5;
	bra.uni 	$L__BB6_2;

$L__BB6_2:
$L__tmp23:
	.loc	1 36 13
	and.b64  	%rd8, %rd1, 1;
	setp.ne.s64 	%p6, %rd8, 0;
	not.pred 	%p7, %p6;
	@%p7 bra 	$L__BB6_4;
	bra.uni 	$L__BB6_3;

$L__BB6_3:
$L__tmp24:
	.loc	1 37 17
	ld.u64 	%rd9, [%SP+0];
	add.u64 	%rd10, %SP, 8;
	{ // callseq 10, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd10;
	.param .align 8 .b8 param1[8];
	st.param.b64 	[param1+0], %rd9;
	.param .align 8 .b8 retval0[8];
	call.uni (retval0), 
	_ZNK4Fp64mlES_, 
	(
	param0, 
	param1
	);
	ld.param.b64 	%rd11, [retval0+0];
	} // callseq 10
	st.u64 	[%SP+8], %rd11;
	bra.uni 	$L__BB6_4;
$L__tmp25:

$L__BB6_4:
	.loc	1 39 13
	ld.u64 	%rd12, [%SP+0];
	add.u64 	%rd13, %SP, 0;
	{ // callseq 11, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd13;
	.param .align 8 .b8 param1[8];
	st.param.b64 	[param1+0], %rd12;
	.param .align 8 .b8 retval0[8];
	call.uni (retval0), 
	_ZNK4Fp64mlES_, 
	(
	param0, 
	param1
	);
	ld.param.b64 	%rd14, [retval0+0];
	} // callseq 11
	st.u64 	[%SP+0], %rd14;
	.loc	1 40 13
	shr.u64 	%rd2, %rd1, 1;
$L__tmp26:
	mov.u64 	%rd15, %rd2;
$L__tmp27:
	bra.uni 	$L__BB6_1;
$L__tmp28:

$L__BB6_5:
	.loc	1 42 9
	ld.u64 	%rd3, [%SP+8];
	setp.ne.s64 	%p3, %rd4, 0;
	not.pred 	%p4, %p3;
	not.pred 	%p5, %p4;
	@%p5 bra 	$L__BB6_7;
	bra.uni 	$L__BB6_6;

$L__BB6_6:
	bra.uni 	$L__BB6_7;

$L__BB6_7:
	st.param.b64 	[func_retval0+0], %rd3;
	ret;
$L__tmp29:
$L__func_end6:

}
	// .weak	_Z21_calc_twiddles_bitrevI4Fp64EvPT_RKS1_i
.weak .func _Z21_calc_twiddles_bitrevI4Fp64EvPT_RKS1_i(
	.param .b64 _Z21_calc_twiddles_bitrevI4Fp64EvPT_RKS1_i_param_0,
	.param .b64 _Z21_calc_twiddles_bitrevI4Fp64EvPT_RKS1_i_param_1,
	.param .b32 _Z21_calc_twiddles_bitrevI4Fp64EvPT_RKS1_i_param_2
)
{
	.local .align 8 .b8 	__local_depot7[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<3>;
	.reg .b32 	%r<10>;
	.reg .b64 	%rd<10>;
	.loc	4 19 0
$L__func_begin7:
	.loc	4 19 0


	mov.u64 	%SPL, __local_depot7;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd1, [_Z21_calc_twiddles_bitrevI4Fp64EvPT_RKS1_i_param_0];
	ld.param.u64 	%rd2, [_Z21_calc_twiddles_bitrevI4Fp64EvPT_RKS1_i_param_1];
	ld.param.u32 	%r2, [_Z21_calc_twiddles_bitrevI4Fp64EvPT_RKS1_i_param_2];
$L__tmp30:
	.loc	4 21 5
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %ctaid.x;
	mul.lo.s32 	%r5, %r3, %r4;
	mov.u32 	%r6, %tid.x;
	add.s32 	%r1, %r5, %r6;
$L__tmp31:
	.loc	4 22 5
	setp.ge.u32 	%p1, %r1, %r2;
	not.pred 	%p2, %p1;
	@%p2 bra 	$L__BB7_2;
	bra.uni 	$L__BB7_1;

$L__BB7_1:
	bra.uni 	$L__BB7_3;

$L__BB7_2:
	.loc	4 25 5
	ld.u64 	%rd3, [%rd2];
	st.u64 	[%SP+0], %rd3;
	.loc	4 26 5
	mov.b32 	%r7, %r1;
	mov.b32 	%r8, %r2;
	{ // callseq 12, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.b32 	[param0+0], %r7;
	.param .b32 param1;
	st.param.b32 	[param1+0], %r8;
	.param .b32 retval0;
	call.uni (retval0), 
	_Z13reverse_indexjj, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r9, [retval0+0];
	} // callseq 12
	cvt.u64.u32 	%rd4, %r9;
	add.u64 	%rd5, %SP, 0;
	{ // callseq 13, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd5;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd4;
	.param .align 8 .b8 retval0[8];
	call.uni (retval0), 
	_ZNK4Fp643powEy, 
	(
	param0, 
	param1
	);
	ld.param.b64 	%rd6, [retval0+0];
	} // callseq 13
	cvt.u64.u32 	%rd7, %r1;
	shl.b64 	%rd8, %rd7, 3;
	add.s64 	%rd9, %rd1, %rd8;
	st.u64 	[%rd9], %rd6;
	.loc	4 27 1
	bra.uni 	$L__BB7_3;

$L__BB7_3:
	ret;
$L__tmp32:
$L__func_end7:

}
	// .weak	_Z19_bitrev_permutationI4Fp64EvPKT_PS1_i
.weak .func _Z19_bitrev_permutationI4Fp64EvPKT_PS1_i(
	.param .b64 _Z19_bitrev_permutationI4Fp64EvPKT_PS1_i_param_0,
	.param .b64 _Z19_bitrev_permutationI4Fp64EvPKT_PS1_i_param_1,
	.param .b32 _Z19_bitrev_permutationI4Fp64EvPKT_PS1_i_param_2
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<10>;
	.reg .b64 	%rd<10>;
	.loc	5 6 0
$L__func_begin8:
	.loc	5 6 0


	ld.param.u64 	%rd1, [_Z19_bitrev_permutationI4Fp64EvPKT_PS1_i_param_0];
	ld.param.u64 	%rd2, [_Z19_bitrev_permutationI4Fp64EvPKT_PS1_i_param_1];
	ld.param.u32 	%r2, [_Z19_bitrev_permutationI4Fp64EvPKT_PS1_i_param_2];
$L__tmp33:
	.loc	5 8 5
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %ctaid.x;
	mul.lo.s32 	%r5, %r3, %r4;
	mov.u32 	%r6, %tid.x;
	add.s32 	%r1, %r5, %r6;
$L__tmp34:
	.loc	5 9 5
	setp.ge.u32 	%p1, %r1, %r2;
	not.pred 	%p2, %p1;
	@%p2 bra 	$L__BB8_2;
	bra.uni 	$L__BB8_1;

$L__BB8_1:
	bra.uni 	$L__BB8_3;

$L__BB8_2:
	.loc	5 12 5
	mov.b32 	%r7, %r1;
	mov.b32 	%r8, %r2;
	{ // callseq 14, 0
	.reg .b32 temp_param_reg;
	.param .b32 param0;
	st.param.b32 	[param0+0], %r7;
	.param .b32 param1;
	st.param.b32 	[param1+0], %r8;
	.param .b32 retval0;
	call.uni (retval0), 
	_Z13reverse_indexjj, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r9, [retval0+0];
	} // callseq 14
	cvt.u64.u32 	%rd3, %r9;
	shl.b64 	%rd4, %rd3, 3;
	add.s64 	%rd5, %rd1, %rd4;
	ld.u64 	%rd6, [%rd5];
	cvt.u64.u32 	%rd7, %r1;
	shl.b64 	%rd8, %rd7, 3;
	add.s64 	%rd9, %rd2, %rd8;
	st.u64 	[%rd9], %rd6;
	.loc	5 13 1
	bra.uni 	$L__BB8_3;

$L__BB8_3:
	ret;
$L__tmp35:
$L__func_end8:

}
	// .globl	radix2_dit_butterfly
.visible .entry radix2_dit_butterfly(
	.param .u64 radix2_dit_butterfly_param_0,
	.param .u64 radix2_dit_butterfly_param_1,
	.param .u32 radix2_dit_butterfly_param_2,
	.param .u32 radix2_dit_butterfly_param_3
)
{
	.local .align 8 .b8 	__local_depot9[16];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<5>;
	.reg .b64 	%rd<8>;
	.loc	6 14 0
$L__func_begin9:
	.loc	6 14 0


	mov.u64 	%SPL, __local_depot9;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd1, [radix2_dit_butterfly_param_0];
	ld.param.u64 	%rd2, [radix2_dit_butterfly_param_1];
	ld.param.u32 	%r1, [radix2_dit_butterfly_param_2];
	ld.param.u32 	%r2, [radix2_dit_butterfly_param_3];
$L__tmp36:
	.loc	6 19 9
	mov.b64 	%rd3, %rd1;
	st.u64 	[%SP+0], %rd3;
	mov.b64 	%rd4, %rd2;
	st.u64 	[%SP+8], %rd4;
	ld.u64 	%rd5, [%SP+8];
	mov.b32 	%r3, %r1;
	mov.b32 	%r4, %r2;
	ld.u64 	%rd6, [%SP+0];
	ld.u64 	%rd7, [%SP+8];
	{ // callseq 15, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd6;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd7;
	.param .b32 param2;
	st.param.b32 	[param2+0], %r3;
	.param .b32 param3;
	st.param.b32 	[param3+0], %r4;
	call.uni 
	_Z21_radix2_dit_butterflyI4Fp64EvPT_PKS1_ii, 
	(
	param0, 
	param1, 
	param2, 
	param3
	);
	} // callseq 15
	.loc	6 20 5
	ret;
$L__tmp37:
$L__func_end9:

}
	// .globl	calc_twiddles
.visible .entry calc_twiddles(
	.param .u64 calc_twiddles_param_0,
	.param .u64 calc_twiddles_param_1,
	.param .u32 calc_twiddles_param_2
)
{
	.local .align 8 .b8 	__local_depot10[16];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<3>;
	.reg .b64 	%rd<8>;
	.loc	6 22 0
$L__func_begin10:
	.loc	6 22 0


	mov.u64 	%SPL, __local_depot10;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd1, [calc_twiddles_param_0];
	ld.param.u64 	%rd2, [calc_twiddles_param_1];
	ld.param.u32 	%r1, [calc_twiddles_param_2];
$L__tmp38:
	.loc	6 24 9
	mov.b64 	%rd3, %rd1;
	st.u64 	[%SP+0], %rd3;
	mov.b64 	%rd4, %rd2;
	st.u64 	[%SP+8], %rd4;
	ld.u64 	%rd5, [%SP+8];
	mov.b32 	%r2, %r1;
	ld.u64 	%rd6, [%SP+0];
	ld.u64 	%rd7, [%SP+8];
	{ // callseq 16, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd6;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd7;
	.param .b32 param2;
	st.param.b32 	[param2+0], %r2;
	call.uni 
	_Z14_calc_twiddlesI4Fp64EvPT_RKS1_i, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 16
	.loc	6 25 5
	ret;
$L__tmp39:
$L__func_end10:

}
	// .globl	calc_twiddles_bitrev
.visible .entry calc_twiddles_bitrev(
	.param .u64 calc_twiddles_bitrev_param_0,
	.param .u64 calc_twiddles_bitrev_param_1,
	.param .u32 calc_twiddles_bitrev_param_2
)
{
	.local .align 8 .b8 	__local_depot11[16];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<3>;
	.reg .b64 	%rd<8>;
	.loc	6 27 0
$L__func_begin11:
	.loc	6 27 0


	mov.u64 	%SPL, __local_depot11;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd1, [calc_twiddles_bitrev_param_0];
	ld.param.u64 	%rd2, [calc_twiddles_bitrev_param_1];
	ld.param.u32 	%r1, [calc_twiddles_bitrev_param_2];
$L__tmp40:
	.loc	6 31 9
	mov.b64 	%rd3, %rd1;
	st.u64 	[%SP+0], %rd3;
	mov.b64 	%rd4, %rd2;
	st.u64 	[%SP+8], %rd4;
	ld.u64 	%rd5, [%SP+8];
	mov.b32 	%r2, %r1;
	ld.u64 	%rd6, [%SP+0];
	ld.u64 	%rd7, [%SP+8];
	{ // callseq 17, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd6;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd7;
	.param .b32 param2;
	st.param.b32 	[param2+0], %r2;
	call.uni 
	_Z21_calc_twiddles_bitrevI4Fp64EvPT_RKS1_i, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 17
	.loc	6 32 5
	ret;
$L__tmp41:
$L__func_end11:

}
	// .globl	bitrev_permutation
.visible .entry bitrev_permutation(
	.param .u64 bitrev_permutation_param_0,
	.param .u64 bitrev_permutation_param_1,
	.param .u32 bitrev_permutation_param_2
)
{
	.local .align 8 .b8 	__local_depot12[16];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<3>;
	.reg .b64 	%rd<8>;
	.loc	6 34 0
$L__func_begin12:
	.loc	6 34 0


	mov.u64 	%SPL, __local_depot12;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd1, [bitrev_permutation_param_0];
	ld.param.u64 	%rd2, [bitrev_permutation_param_1];
	ld.param.u32 	%r1, [bitrev_permutation_param_2];
$L__tmp42:
	.loc	6 39 9
	mov.b64 	%rd3, %rd1;
	st.u64 	[%SP+0], %rd3;
	mov.b64 	%rd4, %rd2;
	st.u64 	[%SP+8], %rd4;
	ld.u64 	%rd5, [%SP+8];
	mov.b32 	%r2, %r1;
	ld.u64 	%rd6, [%SP+0];
	ld.u64 	%rd7, [%SP+8];
	{ // callseq 18, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd6;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd7;
	.param .b32 param2;
	st.param.b32 	[param2+0], %r2;
	call.uni 
	_Z19_bitrev_permutationI4Fp64EvPKT_PS1_i, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 18
	.loc	6 40 5
	ret;
$L__tmp43:
$L__func_end12:

}
	// .weak	_ZN4Fp64C1Ey
.weak .func _ZN4Fp64C1Ey(
	.param .b64 _ZN4Fp64C1Ey_param_0,
	.param .b64 _ZN4Fp64C1Ey_param_1
)
{
	.reg .b64 	%rd<4>;
	.loc	1 10 0
$L__func_begin13:
	.loc	1 10 0


	ld.param.u64 	%rd1, [_ZN4Fp64C1Ey_param_0];
	ld.param.u64 	%rd2, [_ZN4Fp64C1Ey_param_1];
$L__tmp44:
	.loc	1 10 39
	rem.u64 	%rd3, %rd2, -4294967295;
	st.u64 	[%rd1], %rd3;
	ret;
$L__tmp45:
$L__func_end13:

}
.func  (.param .b32 func_retval0) __clz(
	.param .b32 __clz_param_0
)
{
	.reg .b32 	%r<3>;


	ld.param.u32 	%r1, [__clz_param_0];
	clz.b32 	%r2, %r1;
	st.param.b32 	[func_retval0+0], %r2;
	ret;
$L__func_end14:

}
.func  (.param .b32 func_retval0) __brev(
	.param .b32 __brev_param_0
)
{
	.reg .b32 	%r<3>;


	ld.param.u32 	%r1, [__brev_param_0];
	brev.b32 	%r2, %r1;
	st.param.b32 	[func_retval0+0], %r2;
	ret;
$L__func_end15:

}
	.file	1 "/home/e/libprio-rs/lambdaworks/gpu/../math/src/gpu/cuda/shaders/field/./fp_u64.cuh"
	.file	2 "/home/e/libprio-rs/lambdaworks/gpu/../math/src/gpu/cuda/shaders/field/../fft/../utils.h"
	.file	3 "/home/e/libprio-rs/lambdaworks/gpu/../math/src/gpu/cuda/shaders/field/../fft/fft.cuh"
	.file	4 "/home/e/libprio-rs/lambdaworks/gpu/../math/src/gpu/cuda/shaders/field/../fft/twiddles.cuh"
	.file	5 "/home/e/libprio-rs/lambdaworks/gpu/../math/src/gpu/cuda/shaders/field/../fft/bitrev_permutation.cuh"
	.file	6 "/home/e/libprio-rs/lambdaworks/gpu/../math/src/gpu/cuda/shaders/field/fp64.cu"
	.section	.debug_loc
	{
.b64 $L__func_begin6
.b64 $L__tmp21
.b8 6
.b8 0
.b8 144
.b8 181
.b8 200
.b8 201
.b8 171
.b8 2
.b64 $L__tmp21
.b64 $L__tmp22
.b8 7
.b8 0
.b8 144
.b8 181
.b8 226
.b8 144
.b8 147
.b8 215
.b8 4
.b64 $L__tmp22
.b64 $L__tmp26
.b8 6
.b8 0
.b8 144
.b8 177
.b8 200
.b8 201
.b8 171
.b8 2
.b64 $L__tmp26
.b64 $L__tmp27
.b8 6
.b8 0
.b8 144
.b8 178
.b8 200
.b8 201
.b8 171
.b8 2
.b64 $L__tmp27
.b64 $L__func_end6
.b8 7
.b8 0
.b8 144
.b8 181
.b8 226
.b8 144
.b8 147
.b8 215
.b8 4
.b64 0
.b64 0
	}
	.section	.debug_abbrev
	{
.b8 1
.b8 17
.b8 1
.b8 37
.b8 8
.b8 19
.b8 5
.b8 3
.b8 8
.b8 16
.b8 6
.b8 27
.b8 8
.b8 17
.b8 1
.b8 0
.b8 0
.b8 2
.b8 22
.b8 0
.b8 73
.b8 19
.b8 3
.b8 8
.b8 58
.b8 11
.b8 59
.b8 11
.b8 0
.b8 0
.b8 3
.b8 36
.b8 0
.b8 3
.b8 8
.b8 62
.b8 11
.b8 11
.b8 11
.b8 0
.b8 0
.b8 4
.b8 19
.b8 1
.b8 3
.b8 8
.b8 11
.b8 11
.b8 58
.b8 11
.b8 59
.b8 11
.b8 0
.b8 0
.b8 5
.b8 13
.b8 0
.b8 3
.b8 8
.b8 73
.b8 19
.b8 58
.b8 11
.b8 59
.b8 11
.b8 56
.b8 10
.b8 0
.b8 0
.b8 6
.b8 46
.b8 1
.b8 17
.b8 1
.b8 18
.b8 1
.b8 64
.b8 10
.b8 135,64
.b8 8
.b8 3
.b8 8
.b8 58
.b8 11
.b8 59
.b8 11
.b8 73
.b8 19
.b8 63
.b8 12
.b8 0
.b8 0
.b8 7
.b8 5
.b8 0
.b8 2
.b8 10
.b8 51
.b8 11
.b8 3
.b8 8
.b8 58
.b8 11
.b8 59
.b8 11
.b8 73
.b8 19
.b8 0
.b8 0
.b8 8
.b8 11
.b8 1
.b8 17
.b8 1
.b8 18
.b8 1
.b8 0
.b8 0
.b8 9
.b8 52
.b8 0
.b8 51
.b8 11
.b8 2
.b8 10
.b8 3
.b8 8
.b8 58
.b8 11
.b8 59
.b8 11
.b8 73
.b8 19
.b8 0
.b8 0
.b8 10
.b8 52
.b8 0
.b8 2
.b8 10
.b8 51
.b8 11
.b8 3
.b8 8
.b8 58
.b8 11
.b8 59
.b8 11
.b8 73
.b8 19
.b8 0
.b8 0
.b8 11
.b8 5
.b8 0
.b8 2
.b8 10
.b8 51
.b8 11
.b8 3
.b8 8
.b8 73
.b8 19
.b8 0
.b8 0
.b8 12
.b8 5
.b8 0
.b8 51
.b8 11
.b8 2
.b8 10
.b8 3
.b8 8
.b8 58
.b8 11
.b8 59
.b8 11
.b8 73
.b8 19
.b8 0
.b8 0
.b8 13
.b8 5
.b8 0
.b8 2
.b8 6
.b8 3
.b8 8
.b8 58
.b8 11
.b8 59
.b8 11
.b8 73
.b8 19
.b8 0
.b8 0
.b8 14
.b8 59
.b8 0
.b8 3
.b8 8
.b8 0
.b8 0
.b8 15
.b8 15
.b8 0
.b8 73
.b8 19
.b8 51
.b8 6
.b8 0
.b8 0
.b8 16
.b8 38
.b8 0
.b8 73
.b8 19
.b8 0
.b8 0
.b8 17
.b8 16
.b8 0
.b8 73
.b8 19
.b8 51
.b8 6
.b8 0
.b8 0
.b8 0
	}
	.section	.debug_info
	{
.b32 2576
.b8 2
.b8 0
.b32 .debug_abbrev
.b8 8
.b8 1
.b8 108,103,101,110,102,101,58,32,69,68,71,32,54,46,52
.b8 0
.b8 4
.b8 0
.b8 46,46,47,109,97,116,104,47,115,114,99,47,103,112,117,47,99,117,100,97,47,115,104,97,100,101,114,115,47,102,105,101,108,100,47,102,112,54,52,46
.b8 99,117
.b8 0
.b32 .debug_line
.b8 47,104,111,109,101,47,101,47,108,105,98,112,114,105,111,45,114,115,47,108,97,109,98,100,97,119,111,114,107,115,47,103,112,117
.b8 0
.b64 0
.b8 2
.b32 131
.b8 117,54,52
.b8 0
.b8 1
.b8 5
.b8 3
.b8 117,110,115,105,103,110,101,100,32,108,111,110,103,32,108,111,110,103
.b8 0
.b8 7
.b8 8
.b8 4
.b8 70,112,54,52
.b8 0
.b8 8
.b8 1
.b8 7
.b8 5
.b8 105,110,110,101,114
.b8 0
.b32 120
.b8 1
.b8 50
.b8 2
.b8 35
.b8 0
.b8 0
.b8 2
.b32 153
.b8 95,90,78,51,112,54,52,50,70,112,69
.b8 0
.b8 1
.b8 57
.b8 6
.b64 $L__func_begin0
.b64 $L__func_end0
.b8 1
.b8 156
.b8 95,90,49,51,114,101,118,101,114,115,101,95,105,110,100,101,120,106,106
.b8 0
.b8 114,101,118,101,114,115,101,95,105,110,100,101,120
.b8 0
.b8 2
.b8 5
.b32 2480
.b8 1
.b8 7
.b8 5
.b8 144
.b8 180
.b8 228
.b8 149
.b8 1
.b8 2
.b8 105
.b8 0
.b8 2
.b8 5
.b32 2480
.b8 7
.b8 5
.b8 144
.b8 181
.b8 228
.b8 149
.b8 1
.b8 2
.b8 115,105,122,101
.b8 0
.b8 2
.b8 5
.b32 2480
.b8 0
.b8 6
.b64 $L__func_begin1
.b64 $L__func_end1
.b8 1
.b8 156
.b8 95,90,50,49,95,114,97,100,105,120,50,95,100,105,116,95,98,117,116,116,101,114,102,108,121,73,52,70,112,54,52,69,118,80,84,95,80,75,83,49
.b8 95,105,105
.b8 0
.b8 95,114,97,100,105,120,50,95,100,105,116,95,98,117,116,116,101,114,102,108,121,60,70,112,62
.b8 0
.b8 3
.b8 4
.b32 2496
.b8 1
.b8 7
.b8 6
.b8 144
.b8 177
.b8 200
.b8 201
.b8 171
.b8 2
.b8 2
.b8 105,110,112,117,116
.b8 0
.b8 3
.b8 4
.b32 2502
.b8 7
.b8 6
.b8 144
.b8 178
.b8 200
.b8 201
.b8 171
.b8 2
.b8 2
.b8 116,119,105,100,100,108,101,115
.b8 0
.b8 3
.b8 5
.b32 2511
.b8 7
.b8 5
.b8 144
.b8 178
.b8 228
.b8 149
.b8 1
.b8 2
.b8 115,116,97,103,101
.b8 0
.b8 3
.b8 6
.b32 2525
.b8 7
.b8 5
.b8 144
.b8 179
.b8 228
.b8 149
.b8 1
.b8 2
.b8 98,117,116,116,101,114,102,108,121,95,99,111,117,110,116
.b8 0
.b8 3
.b8 7
.b32 2525
.b8 8
.b64 $L__tmp4
.b64 $L__tmp10
.b8 9
.b8 6
.b8 11
.b8 3
.b64 __local_depot1
.b8 35
.b8 0
.b8 119
.b8 0
.b8 3
.b8 20
.b32 179
.b8 9
.b8 6
.b8 11
.b8 3
.b64 __local_depot1
.b8 35
.b8 8
.b8 97
.b8 0
.b8 3
.b8 21
.b32 179
.b8 9
.b8 6
.b8 11
.b8 3
.b64 __local_depot1
.b8 35
.b8 16
.b8 98
.b8 0
.b8 3
.b8 22
.b32 179
.b8 9
.b8 6
.b8 11
.b8 3
.b64 __local_depot1
.b8 35
.b8 24
.b8 114,101,115,95,49
.b8 0
.b8 3
.b8 24
.b32 179
.b8 9
.b8 6
.b8 11
.b8 3
.b64 __local_depot1
.b8 35
.b8 32
.b8 114,101,115,95,50
.b8 0
.b8 3
.b8 25
.b32 179
.b8 10
.b8 5
.b8 144
.b8 177
.b8 228
.b8 149
.b8 1
.b8 2
.b8 116,104,114,101,97,100,95,112,111,115
.b8 0
.b8 3
.b8 9
.b32 2530
.b8 10
.b8 5
.b8 144
.b8 184
.b8 228
.b8 149
.b8 1
.b8 2
.b8 104,97,108,102,95,103,114,111,117,112,95,115,105,122,101
.b8 0
.b8 3
.b8 14
.b32 2530
.b8 10
.b8 5
.b8 144
.b8 185
.b8 228
.b8 149
.b8 1
.b8 2
.b8 103,114,111,117,112
.b8 0
.b8 3
.b8 15
.b32 2530
.b8 10
.b8 6
.b8 144
.b8 177
.b8 226
.b8 200
.b8 171
.b8 2
.b8 2
.b8 112,111,115,95,105,110,95,103,114,111,117,112
.b8 0
.b8 3
.b8 17
.b32 2530
.b8 10
.b8 6
.b8 144
.b8 179
.b8 226
.b8 200
.b8 171
.b8 2
.b8 2
.b8 105
.b8 0
.b8 3
.b8 18
.b32 2530
.b8 0
.b8 0
.b8 6
.b64 $L__func_begin2
.b64 $L__func_end2
.b8 1
.b8 156
.b8 95,90,78,75,52,70,112,54,52,112,108,69,83,95
.b8 0
.b8 111,112,101,114,97,116,111,114,43
.b8 0
.b8 1
.b8 14
.b32 153
.b8 1
.b8 11
.b8 6
.b8 144
.b8 177
.b8 200
.b8 201
.b8 171
.b8 2
.b8 2
.b8 116,104,105,115
.b8 0
.b32 2542
.b8 12
.b8 6
.b8 11
.b8 3
.b64 __local_depot2
.b8 35
.b8 0
.b8 114,104,115
.b8 0
.b8 1
.b8 14
.b32 2537
.b8 0
.b8 6
.b64 $L__func_begin3
.b64 $L__func_end3
.b8 1
.b8 156
.b8 95,90,78,75,52,70,112,54,52,109,108,69,83,95
.b8 0
.b8 111,112,101,114,97,116,111,114,42
.b8 0
.b8 1
.b8 22
.b32 153
.b8 1
.b8 11
.b8 6
.b8 144
.b8 177
.b8 200
.b8 201
.b8 171
.b8 2
.b8 2
.b8 116,104,105,115
.b8 0
.b32 2542
.b8 12
.b8 6
.b8 11
.b8 3
.b64 __local_depot3
.b8 35
.b8 0
.b8 114,104,115
.b8 0
.b8 1
.b8 22
.b32 2537
.b8 0
.b8 6
.b64 $L__func_begin4
.b64 $L__func_end4
.b8 1
.b8 156
.b8 95,90,78,75,52,70,112,54,52,109,105,69,83,95
.b8 0
.b8 111,112,101,114,97,116,111,114,45
.b8 0
.b8 1
.b8 18
.b32 153
.b8 1
.b8 11
.b8 6
.b8 144
.b8 177
.b8 200
.b8 201
.b8 171
.b8 2
.b8 2
.b8 116,104,105,115
.b8 0
.b32 2542
.b8 12
.b8 6
.b8 11
.b8 3
.b64 __local_depot4
.b8 35
.b8 0
.b8 114,104,115
.b8 0
.b8 1
.b8 18
.b32 2537
.b8 0
.b8 6
.b64 $L__func_begin5
.b64 $L__func_end5
.b8 1
.b8 156
.b8 95,90,49,52,95,99,97,108,99,95,116,119,105,100,100,108,101,115,73,52,70,112,54,52,69,118,80,84,95,82,75,83,49,95,105
.b8 0
.b8 95,99,97,108,99,95,116,119,105,100,100,108,101,115,60,70,112,62
.b8 0
.b8 4
.b8 7
.b32 2496
.b8 1
.b8 7
.b8 6
.b8 144
.b8 177
.b8 200
.b8 201
.b8 171
.b8 2
.b8 2
.b8 114,101,115,117,108,116
.b8 0
.b8 4
.b8 7
.b32 2502
.b8 7
.b8 6
.b8 144
.b8 178
.b8 200
.b8 201
.b8 171
.b8 2
.b8 2
.b8 95,111,109,101,103,97
.b8 0
.b8 4
.b8 7
.b32 2556
.b8 7
.b8 5
.b8 144
.b8 178
.b8 228
.b8 149
.b8 1
.b8 2
.b8 99,111,117,110,116
.b8 0
.b8 4
.b8 7
.b32 2525
.b8 8
.b64 $L__tmp17
.b64 $L__tmp19
.b8 9
.b8 6
.b8 11
.b8 3
.b64 __local_depot5
.b8 35
.b8 0
.b8 111,109,101,103,97
.b8 0
.b8 4
.b8 13
.b32 179
.b8 10
.b8 5
.b8 144
.b8 177
.b8 228
.b8 149
.b8 1
.b8 2
.b8 116,104,114,101,97,100,95,112,111,115
.b8 0
.b8 4
.b8 9
.b32 2480
.b8 0
.b8 0
.b8 6
.b64 $L__func_begin6
.b64 $L__func_end6
.b8 1
.b8 156
.b8 95,90,78,75,52,70,112,54,52,51,112,111,119,69,121
.b8 0
.b8 112,111,119
.b8 0
.b8 1
.b8 32
.b32 153
.b8 1
.b8 11
.b8 6
.b8 144
.b8 180
.b8 200
.b8 201
.b8 171
.b8 2
.b8 2
.b8 116,104,105,115
.b8 0
.b32 2542
.b8 13
.b32 .debug_loc
.b8 101,120,112
.b8 0
.b8 1
.b8 32
.b32 120
.b8 8
.b64 $L__tmp20
.b64 $L__tmp29
.b8 9
.b8 6
.b8 11
.b8 3
.b64 __local_depot6
.b8 35
.b8 0
.b8 98,97,115,101
.b8 0
.b8 1
.b8 33
.b32 153
.b8 9
.b8 6
.b8 11
.b8 3
.b64 __local_depot6
.b8 35
.b8 8
.b8 114,101,115,117,108,116
.b8 0
.b8 1
.b8 34
.b32 153
.b8 0
.b8 0
.b8 6
.b64 $L__func_begin7
.b64 $L__func_end7
.b8 1
.b8 156
.b8 95,90,50,49,95,99,97,108,99,95,116,119,105,100,100,108,101,115,95,98,105,116,114,101,118,73,52,70,112,54,52,69,118,80,84,95,82,75,83,49
.b8 95,105
.b8 0
.b8 95,99,97,108,99,95,116,119,105,100,100,108,101,115,95,98,105,116,114,101,118,60,70,112,62
.b8 0
.b8 4
.b8 19
.b32 2496
.b8 1
.b8 7
.b8 6
.b8 144
.b8 177
.b8 200
.b8 201
.b8 171
.b8 2
.b8 2
.b8 114,101,115,117,108,116
.b8 0
.b8 4
.b8 19
.b32 2502
.b8 7
.b8 6
.b8 144
.b8 178
.b8 200
.b8 201
.b8 171
.b8 2
.b8 2
.b8 95,111,109,101,103,97
.b8 0
.b8 4
.b8 19
.b32 2556
.b8 7
.b8 5
.b8 144
.b8 178
.b8 228
.b8 149
.b8 1
.b8 2
.b8 99,111,117,110,116
.b8 0
.b8 4
.b8 19
.b32 2525
.b8 8
.b64 $L__tmp30
.b64 $L__tmp32
.b8 9
.b8 6
.b8 11
.b8 3
.b64 __local_depot7
.b8 35
.b8 0
.b8 111,109,101,103,97
.b8 0
.b8 4
.b8 25
.b32 179
.b8 10
.b8 5
.b8 144
.b8 177
.b8 228
.b8 149
.b8 1
.b8 2
.b8 116,104,114,101,97,100,95,112,111,115
.b8 0
.b8 4
.b8 21
.b32 2480
.b8 0
.b8 0
.b8 6
.b64 $L__func_begin8
.b64 $L__func_end8
.b8 1
.b8 156
.b8 95,90,49,57,95,98,105,116,114,101,118,95,112,101,114,109,117,116,97,116,105,111,110,73,52,70,112,54,52,69,118,80,75,84,95,80,83,49,95,105
.b8 0
.b8 95,98,105,116,114,101,118,95,112,101,114,109,117,116,97,116,105,111,110,60,70,112,62
.b8 0
.b8 5
.b8 6
.b32 2496
.b8 1
.b8 7
.b8 6
.b8 144
.b8 177
.b8 200
.b8 201
.b8 171
.b8 2
.b8 2
.b8 105,110,112,117,116
.b8 0
.b8 5
.b8 6
.b32 2511
.b8 7
.b8 6
.b8 144
.b8 178
.b8 200
.b8 201
.b8 171
.b8 2
.b8 2
.b8 114,101,115,117,108,116
.b8 0
.b8 5
.b8 6
.b32 2502
.b8 7
.b8 5
.b8 144
.b8 178
.b8 228
.b8 149
.b8 1
.b8 2
.b8 108,101,110
.b8 0
.b8 5
.b8 6
.b32 2525
.b8 8
.b64 $L__tmp33
.b64 $L__tmp35
.b8 10
.b8 5
.b8 144
.b8 177
.b8 228
.b8 149
.b8 1
.b8 2
.b8 116,104,114,101,97,100,95,112,111,115
.b8 0
.b8 5
.b8 8
.b32 2480
.b8 0
.b8 0
.b8 6
.b64 $L__func_begin9
.b64 $L__func_end9
.b8 1
.b8 156
.b8 114,97,100,105,120,50,95,100,105,116,95,98,117,116,116,101,114,102,108,121
.b8 0
.b8 114,97,100,105,120,50,95,100,105,116,95,98,117,116,116,101,114,102,108,121
.b8 0
.b8 6
.b8 14
.b32 2496
.b8 1
.b8 7
.b8 9
.b8 3
.b64 radix2_dit_butterfly_param_0
.b8 7
.b8 105,110,112,117,116
.b8 0
.b8 6
.b8 14
.b32 2502
.b8 7
.b8 9
.b8 3
.b64 radix2_dit_butterfly_param_1
.b8 7
.b8 116,119,105,100,100,108,101,115
.b8 0
.b8 6
.b8 15
.b32 2511
.b8 7
.b8 9
.b8 3
.b64 radix2_dit_butterfly_param_2
.b8 7
.b8 115,116,97,103,101
.b8 0
.b8 6
.b8 16
.b32 2525
.b8 7
.b8 9
.b8 3
.b64 radix2_dit_butterfly_param_3
.b8 7
.b8 98,117,116,116,101,114,102,108,121,95,99,111,117,110,116
.b8 0
.b8 6
.b8 17
.b32 2525
.b8 0
.b8 6
.b64 $L__func_begin10
.b64 $L__func_end10
.b8 1
.b8 156
.b8 99,97,108,99,95,116,119,105,100,100,108,101,115
.b8 0
.b8 99,97,108,99,95,116,119,105,100,100,108,101,115
.b8 0
.b8 6
.b8 22
.b32 2496
.b8 1
.b8 7
.b8 9
.b8 3
.b64 calc_twiddles_param_0
.b8 7
.b8 114,101,115,117,108,116
.b8 0
.b8 6
.b8 22
.b32 2502
.b8 7
.b8 9
.b8 3
.b64 calc_twiddles_param_1
.b8 7
.b8 95,111,109,101,103,97
.b8 0
.b8 6
.b8 22
.b32 2556
.b8 7
.b8 9
.b8 3
.b64 calc_twiddles_param_2
.b8 7
.b8 99,111,117,110,116
.b8 0
.b8 6
.b8 22
.b32 2525
.b8 0
.b8 6
.b64 $L__func_begin11
.b64 $L__func_end11
.b8 1
.b8 156
.b8 99,97,108,99,95,116,119,105,100,100,108,101,115,95,98,105,116,114,101,118
.b8 0
.b8 99,97,108,99,95,116,119,105,100,100,108,101,115,95,98,105,116,114,101,118
.b8 0
.b8 6
.b8 27
.b32 2496
.b8 1
.b8 7
.b8 9
.b8 3
.b64 calc_twiddles_bitrev_param_0
.b8 7
.b8 114,101,115,117,108,116
.b8 0
.b8 6
.b8 27
.b32 2502
.b8 7
.b8 9
.b8 3
.b64 calc_twiddles_bitrev_param_1
.b8 7
.b8 95,111,109,101,103,97
.b8 0
.b8 6
.b8 28
.b32 2556
.b8 7
.b8 9
.b8 3
.b64 calc_twiddles_bitrev_param_2
.b8 7
.b8 99,111,117,110,116
.b8 0
.b8 6
.b8 29
.b32 2525
.b8 0
.b8 6
.b64 $L__func_begin12
.b64 $L__func_end12
.b8 1
.b8 156
.b8 98,105,116,114,101,118,95,112,101,114,109,117,116,97,116,105,111,110
.b8 0
.b8 98,105,116,114,101,118,95,112,101,114,109,117,116,97,116,105,111,110
.b8 0
.b8 6
.b8 34
.b32 2496
.b8 1
.b8 7
.b8 9
.b8 3
.b64 bitrev_permutation_param_0
.b8 7
.b8 105,110,112,117,116
.b8 0
.b8 6
.b8 35
.b32 2511
.b8 7
.b8 9
.b8 3
.b64 bitrev_permutation_param_1
.b8 7
.b8 114,101,115,117,108,116
.b8 0
.b8 6
.b8 36
.b32 2502
.b8 7
.b8 9
.b8 3
.b64 bitrev_permutation_param_2
.b8 7
.b8 108,101,110
.b8 0
.b8 6
.b8 37
.b32 2525
.b8 0
.b8 6
.b64 $L__func_begin13
.b64 $L__func_end13
.b8 1
.b8 156
.b8 95,90,78,52,70,112,54,52,67,49,69,121
.b8 0
.b8 70,112,54,52
.b8 0
.b8 1
.b8 10
.b32 2496
.b8 1
.b8 11
.b8 6
.b8 144
.b8 177
.b8 200
.b8 201
.b8 171
.b8 2
.b8 2
.b8 116,104,105,115
.b8 0
.b32 2565
.b8 7
.b8 6
.b8 144
.b8 178
.b8 200
.b8 201
.b8 171
.b8 2
.b8 2
.b8 118
.b8 0
.b8 1
.b8 10
.b32 120
.b8 0
.b8 3
.b8 117,110,115,105,103,110,101,100,32,105,110,116
.b8 0
.b8 7
.b8 4
.b8 14
.b8 118,111,105,100
.b8 0
.b8 15
.b32 179
.b32 12
.b8 15
.b32 2520
.b32 12
.b8 16
.b32 179
.b8 16
.b32 2530
.b8 3
.b8 105,110,116
.b8 0
.b8 5
.b8 4
.b8 16
.b32 153
.b8 16
.b32 2547
.b8 15
.b32 2537
.b32 12
.b8 17
.b32 2520
.b32 12
.b8 16
.b32 2570
.b8 15
.b32 153
.b32 12
.b8 0
	}
	.section	.debug_macinfo
	{
.b8 0

	}
